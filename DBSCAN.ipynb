{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnFkcspmsibbRAVT4ALlY1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShirishaReddyV/AI-Sandbox/blob/main/DBSCAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Step 1: Download dataset\n",
        "path = kagglehub.dataset_download(\"subhajournal/android-malware-detection\")\n",
        "print(\"Dataset Path:\", path)\n",
        "\n",
        "# Step 2: Load CSV\n",
        "csv_file = None\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".csv\"):\n",
        "        csv_file = os.path.join(path, file)\n",
        "        break\n",
        "\n",
        "if csv_file is None:\n",
        "    raise FileNotFoundError(\"No CSV file found in downloaded dataset!\")\n",
        "\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Step 3: Take only top 20,000 rows\n",
        "df = df.head(20000)\n",
        "print(\"Dataset shape after limiting to top 20,000 rows:\", df.shape)\n",
        "\n",
        "# Step 4: Z-Score Based Outlier Summary\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "df_numeric = df[numeric_cols]\n",
        "\n",
        "z_scores = df_numeric.apply(zscore)\n",
        "outliers = (z_scores > 2.5) | (z_scores < -2.5)\n",
        "outlier_summary = outliers.sum().sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nTop numerical columns with outliers:\")\n",
        "print(outlier_summary.head())\n",
        "\n",
        "# Step 5: DBSCAN on top 3 numerical features with most outliers\n",
        "top_relevant_cols = outlier_summary[outlier_summary > 0].head(3).index.tolist()\n",
        "print(\"\\nTop features used for DBSCAN:\", top_relevant_cols)\n",
        "\n",
        "# Drop NaNs and scale\n",
        "X = df[top_relevant_cols].dropna()\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply DBSCAN\n",
        "dbscan = DBSCAN(eps=0.8, min_samples=5)\n",
        "labels = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels\n",
        "X_dbscan = X.copy()\n",
        "X_dbscan['Cluster'] = labels\n",
        "\n",
        "# Count noise points\n",
        "num_outliers = np.sum(labels == -1)\n",
        "print(f\"\\nDBSCAN detected {num_outliers} outliers (Cluster = -1)\")\n",
        "\n",
        "# Step 6: Visualize DBSCAN clusters using first two features\n",
        "plt.figure(figsize=(10, 6))\n",
        "palette = sns.color_palette(\"bright\", len(set(labels)))\n",
        "sns.scatterplot(data=X_dbscan, x=top_relevant_cols[0], y=top_relevant_cols[1], hue=\"Cluster\", palette=palette)\n",
        "plt.title(\"DBSCAN Clustering and Outlier Detection (Top 20,000 rows)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8aWhZVLTc9GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "result = seasonal_decompose(ts, model='additive')\n",
        "result.plot()\n",
        "plt.suptitle(\"Time Series Decomposition\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CfFN1mhMe4St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "model = ARIMA(ts, order=(5, 1, 0))\n",
        "model_fit = model.fit()\n",
        "\n",
        "forecast_result = model_fit.get_forecast(steps=30)\n",
        "forecast = forecast_result.predicted_mean\n",
        "conf_int = forecast_result.conf_int()\n",
        "\n",
        "# Plot forecast with confidence intervals\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(ts, label='Observed')\n",
        "plt.plot(forecast, label='Forecast', color='red')\n",
        "plt.fill_between(conf_int.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.3)\n",
        "plt.title(\"Forecast with 95% Confidence Intervals\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F8THQTkfeYqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Parse datetime column\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
        "df = df.dropna(subset=['Timestamp'])\n",
        "\n",
        "# Step 2: Set time index\n",
        "df.set_index('Timestamp', inplace=True)\n",
        "\n",
        "# Step 3: Resample time series (e.g., hourly or daily)\n",
        "ts = df.resample('D').size()  # 'H' for hourly, 'D' for daily\n",
        "ts = ts.asfreq('D').fillna(0)\n",
        "\n",
        "# Step 4: Plot time series\n",
        "plt.figure(figsize=(14, 6))\n",
        "ts.plot()\n",
        "plt.title(\"Daily Malware Detection Events\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0pr6MeMAczDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Locate the CSV file from the downloaded folder\n",
        "csv_file = None\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".csv\"):\n",
        "        csv_file = os.path.join(path, file)\n",
        "        break\n",
        "\n",
        "# Load the file\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Show all column names\n",
        "print(\"Column names in dataset:\\n\", df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "NTZo_LkJfAaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all leading/trailing spaces from column names\n",
        "df.columns = df.columns.str.strip()\n"
      ],
      "metadata": {
        "id": "IlIwXN5EhlPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "tgTSkgj6iOAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Clean column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Step 2: Convert 'Timestamp' to datetime\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
        "df = df.dropna(subset=['Timestamp'])  # Drop rows with invalid/missing timestamps\n",
        "\n",
        "# Step 3: Extract time features\n",
        "df['Hour'] = df['Timestamp'].dt.hour\n",
        "df['DayOfWeek'] = df['Timestamp'].dt.dayofweek\n",
        "df['DayName'] = df['Timestamp'].dt.day_name()\n"
      ],
      "metadata": {
        "id": "Ko0G4cpOiQJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.countplot(data=df, x='Hour', palette='magma')\n",
        "plt.title('Malware Attack Frequency by Hour')\n",
        "plt.xlabel('Hour (0-23)')\n",
        "plt.ylabel('Number of Attacks')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l_58KltbiSif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "sns.countplot(data=df, x='DayName', order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], palette='viridis')\n",
        "plt.title('Malware Attack Frequency by Day')\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Number of Attacks')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QKe0ix39iVEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap_data = df.groupby(['DayOfWeek', 'Hour']).size().unstack(fill_value=0)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(heatmap_data, cmap='Reds', annot=True, fmt='d')\n",
        "plt.title('Heatmap of Malware Attacks: Hour vs Day')\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Day of Week (0 = Monday)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v_SoWFDsiXj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "\n",
        "# Step 1: Load and clean data\n",
        "df = pd.read_csv(\"PATH_TO_YOUR_DOWNLOADED_CSV.csv\", low_memory=False)  # <-- Replace with your local path\n",
        "df.columns = df.columns.str.strip()\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
        "df.dropna(subset=['Timestamp'], inplace=True)\n",
        "df['Hour'] = df['Timestamp'].dt.hour\n",
        "df['DayOfWeek'] = df['Timestamp'].dt.dayofweek\n",
        "df['DayName'] = df['Timestamp'].dt.day_name()\n",
        "\n",
        "# Step 2: Z-Score Outlier Detection\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "z_scores = StandardScaler().fit_transform(df[numeric_cols])\n",
        "z_df = pd.DataFrame(z_scores, columns=numeric_cols)\n",
        "outliers = (z_df > 2.5) | (z_df < -2.5)\n",
        "outlier_counts = outliers.sum().sort_values(ascending=False)\n",
        "top_features = outlier_counts.head(3).index.tolist()\n",
        "\n",
        "# Step 3: DBSCAN\n",
        "scaled_top = StandardScaler().fit_transform(df[top_features])\n",
        "df['DBSCAN_Label'] = DBSCAN(eps=0.5, min_samples=5).fit_predict(scaled_top)\n",
        "\n",
        "# Step 4: Plots\n",
        "sns.scatterplot(data=df, x=top_features[0], y=top_features[1], hue='DBSCAN_Label')\n",
        "plt.title(\"DBSCAN Clustering\")\n",
        "plt.savefig(\"dbscan.png\")\n",
        "plt.close()\n",
        "\n",
        "sns.countplot(data=df, x='Hour', palette='magma')\n",
        "plt.title(\"Attacks by Hour\")\n",
        "plt.savefig(\"hourly.png\")\n",
        "plt.close()\n",
        "\n",
        "heatmap_data = df.groupby(['DayOfWeek', 'Hour']).size().unstack(fill_value=0)\n",
        "sns.heatmap(heatmap_data, cmap=\"Reds\", annot=True, fmt=\"d\")\n",
        "plt.title(\"Heatmap: Hour vs Day\")\n",
        "plt.savefig(\"heatmap.png\")\n",
        "plt.close()\n",
        "\n",
        "# Step 5: Word Report\n",
        "doc = Document()\n",
        "doc.add_heading(\"Android Malware Detection Analysis Report\", 0)\n",
        "doc.add_paragraph(\"This report includes Z-score-based outlier detection, DBSCAN clustering, and time-series analysis of attack patterns.\")\n",
        "\n",
        "doc.add_heading(\"1. Outlier Detection\", level=1)\n",
        "doc.add_paragraph(f\"Top features with the most outliers: {', '.join(top_features)}\")\n",
        "\n",
        "doc.add_heading(\"2. DBSCAN Clustering\", level=1)\n",
        "doc.add_paragraph(\"Below is the clustering plot of the top 2 features based on DBSCAN.\")\n",
        "doc.add_picture(\"dbscan.png\", width=Inches(6))\n",
        "\n",
        "doc.add_heading(\"3. Attack Time Distribution\", level=1)\n",
        "doc.add_paragraph(\"Attack distribution over hours of the day:\")\n",
        "doc.add_picture(\"hourly.png\", width=Inches(6))\n",
        "\n",
        "doc.add_paragraph(\"Heatmap of attack frequency by day and hour:\")\n",
        "doc.add_picture(\"heatmap.png\", width=Inches(6))\n",
        "\n",
        "doc.add_heading(\"Conclusion\", level=1)\n",
        "doc.add_paragraph(\"This combined analysis can help in profiling malware behavior, scheduling scans, and designing effective defensive systems.\")\n",
        "\n",
        "doc.save(\"Android_Malware_Report.docx\")\n"
      ],
      "metadata": {
        "id": "OWf4v03biabv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3KkS83Gv_Ju5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcf88b51"
      },
      "source": [
        "%pip install python-docx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65ce750a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "\n",
        "# Step 1: Load and clean data - This step is removed as df is already available\n",
        "\n",
        "# Step 2: Z-Score Outlier Detection\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "z_scores = StandardScaler().fit_transform(df[numeric_cols])\n",
        "z_df = pd.DataFrame(z_scores, columns=numeric_cols)\n",
        "outliers = (z_df > 2.5) | (z_df < -2.5)\n",
        "outlier_counts = outliers.sum().sort_values(ascending=False)\n",
        "top_features = outlier_counts.head(3).index.tolist()\n",
        "\n",
        "# Step 3: DBSCAN\n",
        "# Ensure that the columns in top_features exist in the DataFrame and handle potential NaNs\n",
        "scaled_top = StandardScaler().fit_transform(df[top_features].dropna())\n",
        "df['DBSCAN_Label'] = DBSCAN(eps=0.5, min_samples=5).fit_predict(scaled_top)\n",
        "\n",
        "# Step 4: Plots\n",
        "# Ensure that the columns in top_features exist in the DataFrame\n",
        "sns.scatterplot(data=df, x=top_features[0], y=top_features[1], hue='DBSCAN_Label')\n",
        "plt.title(\"DBSCAN Clustering\")\n",
        "plt.savefig(\"dbscan.png\")\n",
        "plt.close()\n",
        "\n",
        "sns.countplot(data=df, x='Hour', palette='magma')\n",
        "plt.title(\"Attacks by Hour\")\n",
        "plt.savefig(\"hourly.png\")\n",
        "plt.close()\n",
        "\n",
        "heatmap_data = df.groupby(['DayOfWeek', 'Hour']).size().unstack(fill_value=0)\n",
        "sns.heatmap(heatmap_data, cmap=\"Reds\", annot=True, fmt=\"d\")\n",
        "plt.title(\"Heatmap: Hour vs Day\")\n",
        "plt.savefig(\"heatmap.png\")\n",
        "plt.close()\n",
        "\n",
        "# Step 5: Word Report\n",
        "doc = Document()\n",
        "doc.add_heading(\"Android Malware Detection Analysis Report\", 0)\n",
        "doc.add_paragraph(\"This report includes Z-score-based outlier detection, DBSCAN clustering, and time-series analysis of attack patterns.\")\n",
        "\n",
        "doc.add_heading(\"1. Outlier Detection\", level=1)\n",
        "doc.add_paragraph(f\"Top features with the most outliers: {', '.join(top_features)}\")\n",
        "\n",
        "doc.add_heading(\"2. DBSCAN Clustering\", level=1)\n",
        "doc.add_paragraph(\"Below is the clustering plot of the top 2 features based on DBSCAN.\")\n",
        "doc.add_picture(\"dbscan.png\", width=Inches(6))\n",
        "\n",
        "doc.add_heading(\"3. Attack Time Distribution\", level=1)\n",
        "doc.add_paragraph(\"Attack distribution over hours of the day:\")\n",
        "doc.add_picture(\"hourly.png\", width=Inches(6))\n",
        "\n",
        "doc.add_paragraph(\"Heatmap of attack frequency by day and hour:\")\n",
        "doc.add_picture(\"heatmap.png\", width=Inches(6))\n",
        "\n",
        "doc.add_heading(\"Conclusion\", level=1)\n",
        "doc.add_paragraph(\"This combined analysis can help in profiling malware behavior, scheduling scans, and designing effective defensive systems.\")\n",
        "\n",
        "doc.save(\"Android_Malware_Report.docx\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}